{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow 6강. File load in Tensorflow and Queue Thread\n",
    "##### https://www.youtube.com/watch?v=hPkmxczEj6k&index=6&list=PL1H8jIvbSo1qOtjQXFzBxMWjL_Gc5x3yG&t=940s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'C:\\\\kimhk\\\\workspace\\\\program\\\\Python\\\\IPNB/images.jpeg'\n",
      "b'C:\\\\kimhk\\\\workspace\\\\program\\\\Python\\\\IPNB/label.csv:1'\n"
     ]
    }
   ],
   "source": [
    "image_dir=os.getcwd()+\"/images.jpeg\"\n",
    "label_dir=os.getcwd()+\"/label.csv\"\n",
    "\n",
    "imagenmae_list=[image_dir]\n",
    "labelnmae_list=[label_dir]\n",
    "\n",
    "imagenmae_queue = tf.train.string_input_producer(imagenmae_list)\n",
    "labelnmae_queue = tf.train.string_input_producer(labelnmae_list)\n",
    "\n",
    "image_reader = tf.WholeFileReader()\n",
    "label_reader = tf.TextLineReader()\n",
    "\n",
    "image_key, image_value = image_reader.read(imagenmae_queue)\n",
    "label_key, label_value = label_reader.read(labelnmae_queue)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)    \n",
    "    print(sess.run(image_key))\n",
    "    print(sess.run(label_key))    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n",
    "\n",
    "image =tf.image.decode_png(image_value)\n",
    "label =tf.decode_csv(label_value,record_defaults= [[0]])\n",
    "\n",
    "x= tf.cast(image, tf.float32)\n",
    "y_ = tf.cast(label, tf.float32)\n",
    "y_ = tf.reshape(y_,[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(1, 1), dtype=float32)\n",
      "0.12.1\n"
     ]
    }
   ],
   "source": [
    "print(y_)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_width = 49\n",
    "image_hight = 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x = tf.placeholder(tf.float32,shape=[None,image_width,image_hight ])\n",
    "#y_ = tf.placeholder(tf.float32,shape=[None,1]) # 정답데이터가 몇 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hidden1 convolution\n",
    "hidden1_w = tf.Variable(tf.truncated_normal([5,5,1,32]))\n",
    "hidden1_b = tf.Variable(tf.zeros([32]))\n",
    "\n",
    "x_image = tf.reshape(x, [-1, image_width, image_hight,1])\n",
    "\n",
    "h1=tf.nn.relu(tf.nn.conv2d(x_image, hidden1_w, strides=[1,1,1,1], padding=\"SAME\" ) +hidden1_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hidden2 convolution\n",
    "hidden2_w = tf.Variable(tf.truncated_normal([5,5,32,64]))\n",
    "hidden2_b = tf.Variable(tf.zeros([64]))\n",
    "\n",
    "h2=tf.nn.relu(tf.nn.conv2d(h1, hidden2_w, strides=[1,1,1,1], padding=\"SAME\" ) + hidden2_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_flat = tf.reshape(h2, [-1, 49*61*64])\n",
    "fc_w = tf.Variable(tf.truncated_normal([49*61*64,10]))\n",
    "fc_b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "h_fc1= tf.nn.relu(tf.matmul(h_flat, fc_w) + fc_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_2:0\", shape=(?, 191296), dtype=float32)\n",
      "Tensor(\"Variable_4/read:0\", shape=(191296, 10), dtype=float32)\n",
      "Tensor(\"Variable_5/read:0\", shape=(10,), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(h_flat)\n",
    "print(fc_w)\n",
    "print(fc_b)\n",
    "print(h_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_w = tf.Variable(tf.truncated_normal([10,1]))\n",
    "out_b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "pred = tf.matmul(h_fc1, out_w) + out_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cross_entropy \n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(pred, y_))\n",
    "train = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#[T,T,F,F,F,F,T] BOOL\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 4.55189e+06\n",
      "acc: 1.0\n",
      "loss: 2.93801e+06\n",
      "acc: 1.0\n",
      "loss: 1.31773e+06\n",
      "acc: 1.0\n",
      "loss: -274039.0\n",
      "acc: 1.0\n",
      "loss: -1.72929e+06\n",
      "acc: 1.0\n",
      "loss: -3.1803e+06\n",
      "acc: 1.0\n",
      "loss: -4.62626e+06\n",
      "acc: 1.0\n",
      "loss: -6.06903e+06\n",
      "acc: 1.0\n",
      "loss: -7.30265e+06\n",
      "acc: 1.0\n",
      "loss: -8.41133e+06\n",
      "acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(10):\n",
    "        sess.run(train)   \n",
    "        cost, acc =  sess.run([loss, accuracy])   \n",
    "        print(\"loss:\",cost)  \n",
    "        print(\"acc:\",acc)       \n",
    "            \n",
    "    #image = sess.run(image)\n",
    "    #print(image)\n",
    "    #Image.fromarray(image).show()\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
