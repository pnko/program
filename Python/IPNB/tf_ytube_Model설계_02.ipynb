{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YouTube  Tensorflow 2강. Model 설계하기\n",
    "##### https://www.youtube.com/watch?v=eQ-UHjyvEck&index=2&list=PL1H8jIvbSo1qOtjQXFzBxMWjL_Gc5x3yG\n",
    "\n",
    "### 1 .Model 만든 후 트레이닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = [[1,5,3,7,8,10,12],\n",
    "              [5,8,10,3,9,7,1]\n",
    "             ]\n",
    "label_data = [[0,0,0,1,0],\n",
    "             [1,0,0,0,0]\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = 7\n",
    "HIDDEN1_SIZE = 10\n",
    "HIDDEN2_SIZE = 8\n",
    "CLASSES = 5\n",
    "Leaning_Rate= 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,INPUT_SIZE])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None,CLASSES])\n",
    "tensor_map={x:input_data, y_: label_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Model 설계(Weight 설계) 파라미터 설정, 모델 설정\n",
    "# hiddn 1 레이어\n",
    "w_h1 = tf.Variable(tf.truncated_normal(shape=[INPUT_SIZE, HIDDEN1_SIZE]),dtype=tf.float32)\n",
    "b_h1 = tf.Variable(tf.zeros(shape=[HIDDEN1_SIZE]), dtype=tf.float32)\n",
    "#hidden1 = tf.matmul(x , w_h1) + b_h1 #선형 회귀 모델\n",
    "hidden1 = tf.sigmoid(tf.matmul(x , w_h1) + b_h1) #simoid를 이용한 로지스틱 회귀 모델(현재 데이터는 로지스틱)\n",
    "\n",
    "# hiddn 2 레이어\n",
    "w_h2 = tf.Variable(tf.truncated_normal(shape=[HIDDEN1_SIZE, HIDDEN2_SIZE]),dtype=tf.float32)\n",
    "b_h2 = tf.Variable(tf.zeros(shape=[HIDDEN2_SIZE]), dtype=tf.float32)\n",
    "#hidden2 = tf.matmul(hidden1, w_h2) + b_h2\n",
    "hidden2 = tf.sigmoid(tf.matmul(hidden1, w_h2) + b_h2)\n",
    "\n",
    "# hiddn 마지막 레이어\n",
    "w_o = tf.Variable(tf.truncated_normal(shape=[HIDDEN2_SIZE, CLASSES]),dtype=tf.float32)\n",
    "b_o= tf.Variable(tf.zeros(shape=[CLASSES]), dtype=tf.float32)\n",
    "#y = tf.matmul(hidden2, w_o) + b_o\n",
    "y = tf.sigmoid(tf.matmul(hidden2, w_o) + b_o)\n",
    "\n",
    "# 참고 : sigmoid 의 정규화한 것이 softmax  softmax 와 label 과 비교해서 얼마나 다른지 비교함.(PredDiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cost function 정의 : cress 엔트로피\n",
    "#y = 예측값\n",
    "#cost = -y_*tf.log(y)-(1-y_)*tf.log(1-y)\n",
    "#cost = tf.reduce_sum(-y_*tf.log(y)-(1-y_)*tf.log(1-y))\n",
    "cost = tf.reduce_mean(-y_*tf.log(y)-(1-y_)*tf.log(1-y))\n",
    "\n",
    "#cost 최적화 , gradiend decsent(기울기 상승) , minizie 작은값\n",
    "train = tf.train.GradientDescentOptimizer(Leaning_Rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0\n",
      "Loss:  0.606537\n",
      "Step:  100\n",
      "Loss:  0.381184\n",
      "Step:  200\n",
      "Loss:  0.32418\n",
      "Step:  300\n",
      "Loss:  0.27916\n",
      "Step:  400\n",
      "Loss:  0.258992\n",
      "Step:  500\n",
      "Loss:  0.242328\n",
      "Step:  600\n",
      "Loss:  0.227167\n",
      "Step:  700\n",
      "Loss:  0.21281\n",
      "Step:  800\n",
      "Loss:  0.198998\n",
      "Step:  900\n",
      "Loss:  0.185682\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "#print(sess.run(cost, feed_dict=tensor_map))\n",
    "\n",
    "for i in range(1000):\n",
    "    _,loss = sess.run([train,cost], feed_dict=tensor_map)\n",
    "    if i % 100 == 0 :\n",
    "        print(\"Step: \", i)\n",
    "        print(\"Loss: \", loss)\n",
    "sess.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 02. Model 테스트 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
